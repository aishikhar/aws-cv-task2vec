{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task2vec import Task2Vec\n",
    "from models import get_model\n",
    "import datasets\n",
    "import task_similarity\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synbols_utils import Synbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = torch.load('all.pt')\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ref = pd.read_csv('ref.csv', index_col = 0)\n"
   ]
  },
  {
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add Task2Vec as part of the SingleHead Class\n",
    "\n",
    "class AttentionNet(nn.Module):\n",
    "    \"\"\"Soft-Attention on the Embedding z\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(inplace=True), #FIXME Try Tanh as well\n",
    "            nn.Linear(latent_dim,input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention(x)\n",
    "        return F.softmax(x)\n",
    "\n",
    "\n",
    "class AttentionRawList(nn.Module):\n",
    "    \"\"\"Attention through Raw Params\n",
    "            Input: Param shape, No of Params\"\"\"\n",
    "    def __init__(self, shape, N):\n",
    "        super(AttentionRaw, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn((shape))) for _ in range(N)])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.params[index]\n",
    "\n",
    "    def forward(self, index, x):\n",
    "        # Weighted/Atttention on x using Attention 'i'\n",
    "        return self.params[index] * x \n",
    "\n",
    "class AttentionRaw(nn.Module):\n",
    "    \"\"\"Attention through Raw Params\n",
    "            Input: Param shape, No of Params\"\"\"\n",
    "    def __init__(self, shape):\n",
    "        super(AttentionRaw, self).__init__()\n",
    "        # Attention Params: Shape N_attn, M as N Attentions of dimension M \n",
    "        self.params = nn.Parameter(torch.randn(N, task2vec_dim), requires_grad = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Weighted/Atttention on x using Attention 'i'\n",
    "        # X shape: N_z, M, Params shape: N_attn, M\n",
    "        # Do Element wise multiplication\n",
    "        return torch.mul(torch.unsqueeze(self.params, 1), x) "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = [z.hessian for z in saved]\n",
    "task2vec_dim = Z[0].shape[0]\n",
    "latent_dim = 128\n",
    "N = 4 # No of attributes\n",
    "M = len(Z) # No of Task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_tensor = torch.tensor(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attns = AttentionRaw((N, task2vec_dim)) #AttentionRawList(task2vec_dim, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attns_z_matrix = attns(Z_tensor)"
   ]
  },
  {
   "source": [
    "import numpy as np\n",
    "attns_query = torch.mm(attns.params, Z_tensor.T) / np.sqrt(1384)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "attn_ = F.softmax(attns_query, 0)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Z_tensor.shape"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "batch_size = 1024\n",
    "q_len = 32\n",
    "v_len = 32\n",
    "hidden_dim = 128\n",
    "k_len = 32\n",
    "query = torch.randn((batch_size, q_len, hidden_dim)) # q_len, hidden_dim @ hidden_dim, k_len \n",
    "key = torch.randn((batch_size, k_len, hidden_dim))\n",
    "value = torch.randn((batch_size, v_len, hidden_dim))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "score = torch.bmm(query, key.transpose(1, 2)) / np.sqrt(hidden_dim)\n",
    "attn = F.softmax(score, -1)\n",
    "context = torch.bmm(attn, value)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Attentions.cuda()\n",
    "Z_loader = torch.utils.data.DataLoader(Z, batch_size = len(Z))\n",
    "optimizer = torch.optim.Adam(attns.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, batch in enumerate(Z_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = attns(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _similarity_matrix(attrs, epsilon = 1e-8):\n",
    "    norm = attrs.norm(dim = -1, keepdim = True)\n",
    "    norm = torch.maximum(norm, 1e-8 * torch.ones(norm.shape))\n",
    "    attrs = attrs / norm\n",
    "    temp = attrs.view(attrs.shape[0], attrs.shape[1],1,1,attrs.shape[2])\n",
    "    similarity_matrix = torch.mul(temp,attrs).sum(axis = -1)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = _similarity_matrix(attrs)"
   ]
  },
  {
   "source": [
    "## Sample "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attns: torch.Size([3, 2]), Z: torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "Attns = [[0.5, 0.5], [0.2, 0.8], [0.1, 0.9]] # Three Attns 3x2\n",
    "Z = [[1,2],[3,4],[5,6],[7,8],[9,10]] # 5 z vectors. 5 x 2\n",
    "Attns = torch.tensor(Attns)\n",
    "Z = torch.tensor(Z)\n",
    "print(f\"Attns: {Attns.shape}, Z: {Z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(Attns, Z):\n",
    "    return torch.mul(torch.unsqueeze(Attns, 1), Z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "Attrs = forward_pass(Attns, Z)\n",
    "Attrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(A,B, eps=1e-8, ):\n",
    "    A_norm = A.norm(dim = -1, keepdim = True)\n",
    "    B_norm = B.norm(dim = -1, keepdim = True)\n",
    "    A_norm = torch.maximum(A_norm, eps * torch.ones(A_norm.shape))\n",
    "    B_norm = torch.maximum(B_norm, eps * torch.ones(B_norm.shape))\n",
    "    A = torch.div(A,A_norm)\n",
    "    B = torch.div(B,B_norm)\n",
    "    return torch.mm(A,B.T)\n",
    "cos_sim(Attrs[0],Attrs[0]).flatten().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_unitvectors(M, eps = 1e-8):\n",
    "    M_norm = M.norm(dim = -1, keepdim = True)\n",
    "    M_norm = torch.maximum(M_norm, eps * torch.ones(M_norm.shape))\n",
    "    return torch.div(M, M_norm)\n",
    "def positives(Attrs):\n",
    "    M = norm_unitvectors(Attrs)\n",
    "    M_trans = M.transpose(1,2)\n",
    "    return torch.bmm(M, M_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9839, 0.9734, 0.9676, 0.9640, 0.9839, 1.0000, 0.9987, 0.9972,\n",
       "        0.9960, 0.9734, 0.9987, 1.0000, 0.9997, 0.9993, 0.9676, 0.9972, 0.9997,\n",
       "        1.0000, 0.9999, 0.9640, 0.9960, 0.9993, 0.9999, 1.0000])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.9430, 0.9615, 0.9668, 0.9693, 0.9708, 0.8682, 0.8969, 0.9056, 0.9097,\n",
       "        0.9122, 0.8417, 0.8730, 0.8826, 0.8873, 0.8900, 0.8284, 0.8610, 0.8711,\n",
       "        0.8759, 0.8788, 0.8205, 0.8538, 0.8641, 0.8691, 0.8720])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# Positives\n",
    "# sim(Attr[i], Attr[j]) = 1 | -1 \n",
    "# |sim(Attr[i], Attr[j])| = 1\n",
    "# for all i, and i = j\n",
    "\n",
    "# Negatives or Zero\n",
    "#   Negatives:\n",
    "#       sim(Attr[i], Attr[j]) for all i=/j\n",
    "\n",
    "# or induce Orthogonality as   Zero:\n",
    "#   sim(Attr[i], Attr[j]) = 0\n",
    "\n",
    "\n",
    "\n",
    "def positives(Attrs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 3, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "cos_matrix = _similarity_matrix(Attrs)\n",
    "cos_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9839, 0.9734, 0.9676, 0.9640],\n",
       "        [0.9430, 0.9615, 0.9668, 0.9693, 0.9708],\n",
       "        [0.9179, 0.9285, 0.9318, 0.9335, 0.9345]])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "cos_matrix[0][:][0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 135])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "i = 0\n",
    "j = 6\n",
    "k = 6\n",
    "similarity_matrix[i][:][i][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positives(sim_matrix, i):\n",
    "    \"\"\"\n",
    "        For all j,k: do summation of cos similarities across matrix for given i\n",
    "        \n",
    "        Note: mat[i][j][i][k] represents sim(att[i][j], att[i][k])\n",
    "        So, for i'th attribute, positives are:\n",
    "            SUM_j,k mat[i][j][i][k]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_loss(similarity_matrix):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch:{epoch}\")\n",
    "    attentions.train()\n",
    "    for batch_ix, Z in enumerate(Z_loader):\n",
    "        optimizer.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"train_loss\", float(loss))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for batch in tqdm(val_loader):\n",
    "            x, y = batch\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            hits += (logits.argmax(-1) == y).float().sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "    print(\"val_loss\", float(loss), \"val_accuracy\", hits / total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd055cd0875620963c5442b7d59b0722375428dccb5a93c2d0c174dd0269f2c2857",
   "display_name": "Python 3.7.10 64-bit ('avalanche-dev-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "metadata": {
   "interpreter": {
    "hash": "32b8663ab9bffaa55100cf14b296808c6a4ccd42b1ae71b1797e390089e5a394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}